{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# [Cell 1] ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° í™˜ê²½ ì„¤ì •\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import yfinance as yf\n",
        "from tqdm.auto import tqdm\n",
        "import warnings\n",
        "import random\n",
        "from scipy.optimize import minimize # í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” í•„ìˆ˜\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class Config:\n",
        "    STOCKS = ['META', 'TSLA', 'NFLX', 'NVDA', 'PLTR', 'MSFT', 'GOOG', 'AAPL', 'AVGO', 'AMZN']\n",
        "    MODEL_ORDER = ['JJH', 'JHP', 'IHK', 'HJK', 'YRK']\n",
        "    START_DATE = '2020-11-02'\n",
        "    TRAIN_END = '2023-12-31'\n",
        "    TEST_START = '2024-01-01'\n",
        "    END_DATE = '2025-10-31'\n",
        "    INITIAL_CAPITAL = 10000.0\n",
        "    META_DATA_PATH = 'meta_training_data_v2.csv'\n",
        "    LOOKBACK = 20\n",
        "\n",
        "def set_all_seeds(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "set_all_seeds()\n",
        "\n",
        "# --- ë°ì´í„° ë¡œë” ---\n",
        "def load_local_files():\n",
        "    print(\"ğŸ“‚ [Smart Loader] ë°ì´í„° ì •ë°€ ë¡œë“œ ì¤‘...\")\n",
        "    search_dir = '/content' if os.path.exists('/content') else '.'\n",
        "    all_files = [f for f in os.listdir(search_dir) if f.endswith('.csv')]\n",
        "    close_dict, volume_dict = {}, {}\n",
        "\n",
        "    for s in Config.STOCKS:\n",
        "        target = next((os.path.join(search_dir, f) for f in all_files if s.upper() in f.upper()), None)\n",
        "        if not target: continue\n",
        "        try:\n",
        "            df = pd.read_csv(target)\n",
        "            if 'Date' in df.columns: df['Date'] = pd.to_datetime(df['Date'])\n",
        "            else: df.rename(columns={df.columns[0]: 'Date'}, inplace=True); df['Date'] = pd.to_datetime(df['Date'])\n",
        "            df = df.set_index('Date').sort_index()\n",
        "            df = df[~df.index.duplicated(keep='last')]\n",
        "\n",
        "            c_col = next((c for c in df.columns if 'close' in c.lower() or 'last' in c.lower()), None)\n",
        "            v_col = next((c for c in df.columns if 'vol' in c.lower()), None)\n",
        "\n",
        "            if c_col: close_dict[s] = df[c_col].astype(str).str.replace(r'[$,]', '', regex=True).astype(float) if df[c_col].dtype==object else df[c_col]\n",
        "            if v_col: volume_dict[s] = df[v_col].astype(str).str.replace(r'[$,]', '', regex=True).astype(float) if df[v_col].dtype==object else df[v_col]\n",
        "        except: pass\n",
        "\n",
        "    if not close_dict: return None, None\n",
        "    c_df = pd.DataFrame(close_dict).fillna(method='ffill').fillna(method='bfill')\n",
        "    # ê±°ë˜ëŸ‰ ê²°ì¸¡ì¹˜ëŠ” 0ìœ¼ë¡œ ì±„ì›€\n",
        "    v_df = pd.DataFrame(volume_dict).fillna(0).reindex(index=c_df.index, columns=c_df.columns).fillna(0)\n",
        "\n",
        "    mask = (c_df.index >= Config.START_DATE) & (c_df.index <= Config.END_DATE)\n",
        "    return c_df.loc[mask], v_df.loc[mask]\n",
        "\n",
        "def load_smart_qqq(target_index):\n",
        "    try:\n",
        "        q = yf.download('QQQ', start=Config.START_DATE, end=Config.END_DATE, progress=False)\n",
        "        if not q.empty:\n",
        "            return q['Close'].reindex(target_index, method='ffill').fillna(method='bfill')\n",
        "    except: pass\n",
        "    return None"
      ],
      "metadata": {
        "id": "nvj6R8ll3okj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [Cell 2] íŒ€ì¥ AI (Gating Network)\n",
        "class MetaWindowDataset(Dataset):\n",
        "    def __init__(self, df, lookback=20, le=None):\n",
        "        self.lookback = lookback\n",
        "        # íŒ€ì¥ì˜ íŒë‹¨ ê·¼ê±°: ì‹œì¥ ê´´ë¦¬ìœ¨, ë³€ë™ì„±, ëª¨ë©˜í…€ + ê° ëª¨ë¸ì˜ ê³¼ê±° ì„±ê³¼\n",
        "        feature_cols = ['Feature_GapMA20', 'Feature_Vol5D', 'Feature_Mom60D']\n",
        "        model_ret_cols = [f'Ret_{m}' for m in Config.MODEL_ORDER]\n",
        "        final_cols = feature_cols + model_ret_cols\n",
        "\n",
        "        self.features = df[final_cols].values\n",
        "        self.num_vars = len(final_cols)\n",
        "\n",
        "        if le is None:\n",
        "            self.le = LabelEncoder()\n",
        "            self.labels = self.le.fit_transform(df['Label_Best_Model'])\n",
        "        else:\n",
        "            self.le = le\n",
        "            self.labels = self.le.transform(df['Label_Best_Model'])\n",
        "\n",
        "    def __len__(self): return len(self.features) - self.lookback\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.features[idx : idx + self.lookback]\n",
        "        y = self.labels[idx + self.lookback]\n",
        "        return torch.FloatTensor(x), torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "class iTransformerGating(nn.Module):\n",
        "    def __init__(self, num_variates, lookback_len=20, d_model=64, num_classes=5):\n",
        "        super(iTransformerGating, self).__init__()\n",
        "        self.enc_embedding = nn.Linear(lookback_len, d_model)\n",
        "        self.encoder = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model, 4, batch_first=True, dropout=0.1), 2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.proj = nn.Linear(num_variates * d_model, num_classes)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "    def forward(self, x):\n",
        "        # (Batch, Lookback, Vars) -> (Batch, Vars, Lookback)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        # iTransformer êµ¬ì¡°: ë³€ìˆ˜ë³„ë¡œ ì„ë² ë”© í›„ Attention\n",
        "        return self.softmax(self.proj(self.flatten(self.encoder(self.enc_embedding(x)))))\n",
        "\n",
        "def train_itransformer_leader():\n",
        "    print(\"ğŸ§  [Team Leader] íŒ€ì¥ í•™ìŠµ ì‹œì‘...\")\n",
        "    path = Config.META_DATA_PATH\n",
        "    if not os.path.exists(path): return None, None, None\n",
        "\n",
        "    df = pd.read_csv(path)\n",
        "    dataset = MetaWindowDataset(df, lookback=Config.LOOKBACK)\n",
        "    loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "    model = iTransformerGating(dataset.num_vars, Config.LOOKBACK, 64, len(dataset.le.classes_)).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    model.train()\n",
        "    for _ in range(30):\n",
        "        for bx, by in loader:\n",
        "            optimizer.zero_grad()\n",
        "            nn.CrossEntropyLoss()(model(bx.to(device)), by.to(device)).backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    return model, dataset.le, dataset.num_vars"
      ],
      "metadata": {
        "id": "ESHUjmaq3qDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [Cell 3] Agent 1 (JJH) & Agent 2 (JHP)\n",
        "\n",
        "# ê³µìš© ì½”ì–´ ëª¨ë“ˆ\n",
        "class iTransformerCore(nn.Module):\n",
        "    def __init__(self, n, l=60, d=64):\n",
        "        super().__init__()\n",
        "        self.e = nn.Linear(l, d)\n",
        "        self.t = nn.TransformerEncoder(nn.TransformerEncoderLayer(d, 4, batch_first=True, dropout=0.1), 2)\n",
        "        self.p = nn.Linear(d, 1)\n",
        "    def forward(self, x): return self.p(self.t(self.e(x.permute(0, 2, 1)))).squeeze(-1)\n",
        "\n",
        "class QuantformerCore(nn.Module):\n",
        "    def __init__(self, i=2, d=32):\n",
        "        super().__init__()\n",
        "        self.e = nn.Linear(i, d)\n",
        "        self.t = nn.TransformerEncoder(nn.TransformerEncoderLayer(d, 4, batch_first=True, dropout=0.1), 2)\n",
        "        self.f = nn.Linear(d, 3) # Bull, Neutral, Bear\n",
        "    def forward(self, x): return nn.Softmax(dim=-1)(self.f(self.t(self.e(x))[:, -1, :]))\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Agent 1: JJH (Alpha Seeker)\n",
        "# íŠ¹ì§•: Rolling Norm -> iTransformer -> Softmax ë¹„ì¤‘\n",
        "# ---------------------------------------------------------\n",
        "class Agent_JJH:\n",
        "    def __init__(self, n):\n",
        "        self.m = iTransformerCore(n).to(device)\n",
        "    def train(self, c, v): pass # Pre-trained ê°€ì •\n",
        "    def trade(self, c, v):\n",
        "        if len(c) < 60: return np.ones(10)/10\n",
        "\n",
        "        # 1. 60ì¼ ìœˆë„ìš° ì •ê·œí™” (í•µì‹¬ ë¡œì§)\n",
        "        raw = c.pct_change().fillna(0).iloc[-60:].values\n",
        "        mean = np.mean(raw, axis=0)\n",
        "        std = np.std(raw, axis=0) + 1e-6\n",
        "        norm = (raw - mean) / std\n",
        "\n",
        "        # 2. ì˜ˆì¸¡\n",
        "        inp = torch.FloatTensor(norm).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            alpha_score = self.m(inp).cpu().numpy()[0]\n",
        "\n",
        "        # 3. ë¹„ì¤‘ ì‚°ì¶œ (Softmax Temperature ì ìš©)\n",
        "        # ë‹¨ìˆœ Top3ê°€ ì•„ë‹ˆë¼, í™•ì‹ ì´ ê°•í• ìˆ˜ë¡ ë¹„ì¤‘ì„ ë†’ê²Œ ì¤Œ\n",
        "        temp = 0.5 # ë‚®ì„ìˆ˜ë¡ ê°•í•œ ì¢…ëª©ì— ëª°ë¹µ\n",
        "        exp_s = np.exp(alpha_score / temp)\n",
        "        w = exp_s / np.sum(exp_s)\n",
        "        return w\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Agent 2: JHP (Direction Classifier)\n",
        "# íŠ¹ì§•: Price + Volume -> Bull í™•ë¥  ê°ì§€\n",
        "# ---------------------------------------------------------\n",
        "class Agent_JHP:\n",
        "    def __init__(self, n):\n",
        "        self.m = QuantformerCore().to(device)\n",
        "        self.stocks = Config.STOCKS\n",
        "    def train(self, c, v): pass\n",
        "    def trade(self, c, v):\n",
        "        if len(c) < 20: return np.ones(10)/10\n",
        "        r = c.pct_change().fillna(0).iloc[-20:]\n",
        "        t = v.pct_change().fillna(0).iloc[-20:] # Turnover proxy\n",
        "\n",
        "        probs = []\n",
        "        for i in range(len(self.stocks)):\n",
        "            q = np.stack([r.iloc[:,i].values, t.iloc[:,i].values], axis=1)\n",
        "            # ì…ë ¥ ì •ê·œí™”\n",
        "            n = (q - q.mean(0)) / (q.std(0) + 1e-8)\n",
        "            with torch.no_grad():\n",
        "                # Class 0: Bull (ìƒìŠ¹) í™•ë¥ ë§Œ ì¶”ì¶œ\n",
        "                prob_bull = self.m(torch.FloatTensor(n).unsqueeze(0).to(device))[0][0].item()\n",
        "                probs.append(prob_bull)\n",
        "\n",
        "        # Bull í™•ë¥ ì— ë¹„ë¡€í•˜ì—¬ ë¹„ì¤‘ í• ë‹¹\n",
        "        w = np.array(probs)\n",
        "        if w.sum() == 0: return np.ones(10)/10\n",
        "        return w / w.sum()"
      ],
      "metadata": {
        "id": "hE7l79tD3rjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [Cell 4] Agent 3: IHK (Portfolio Strategist)\n",
        "# íŠ¹ì§•: 504ì¼ ì¥ê¸° ë°ì´í„° + Sharpe Ratio Maximization\n",
        "class Agent_IHK:\n",
        "    def __init__(self, n):\n",
        "        self.n_stocks = n\n",
        "    def train(self, c, v): pass\n",
        "\n",
        "    def trade(self, c, v):\n",
        "        # 1. 504ì¼ (ì•½ 2ë…„) ë°ì´í„° í™•ë³´\n",
        "        lookback = min(len(c), 504)\n",
        "        if lookback < 60: return np.ones(self.n_stocks) / self.n_stocks\n",
        "\n",
        "        hist_data = c.iloc[-lookback:].pct_change().fillna(0)\n",
        "\n",
        "        # 2. íŒŒë¼ë¯¸í„° ì¶”ì • (ì—°ìœ¨í™”)\n",
        "        mu = hist_data.mean().values * 252\n",
        "        S = hist_data.cov().values * 252\n",
        "\n",
        "        # [ì¤‘ìš”] ê³µë¶„ì‚° í–‰ë ¬ ì•ˆì •í™” (íŠ¹ì´í–‰ë ¬ ì—ëŸ¬ ë°©ì§€)\n",
        "        S = S + np.eye(len(S)) * 1e-6\n",
        "\n",
        "        # 3. ìµœì í™” í•¨ìˆ˜ (Negative Sharpe)\n",
        "        def negative_sharpe(weights, mu, S, rf=0.02):\n",
        "            p_ret = np.sum(weights * mu)\n",
        "            p_vol = np.sqrt(np.dot(weights.T, np.dot(S, weights)))\n",
        "            return -(p_ret - rf) / (p_vol + 1e-6)\n",
        "\n",
        "        # 4. ì œì•½ì¡°ê±´ ë° ì‹¤í–‰\n",
        "        constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
        "        bounds = tuple((0.0, 1.0) for _ in range(self.n_stocks))\n",
        "        init_guess = np.ones(self.n_stocks) / self.n_stocks\n",
        "\n",
        "        try:\n",
        "            # SLSQP ì†”ë²„ ì‚¬ìš©\n",
        "            res = minimize(negative_sharpe, init_guess, args=(mu, S),\n",
        "                           method='SLSQP', bounds=bounds, constraints=constraints, tol=1e-4)\n",
        "            return res.x\n",
        "        except:\n",
        "            # ìµœì í™” ì‹¤íŒ¨ ì‹œ: ì—­ë³€ë™ì„±(Risk Parity) ì „ëµìœ¼ë¡œ íšŒê·€\n",
        "            vol = np.sqrt(np.diag(S))\n",
        "            inv_vol = 1.0 / (vol + 1e-6)\n",
        "            return inv_vol / np.sum(inv_vol)"
      ],
      "metadata": {
        "id": "3C9iBmSn3tjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [Cell 5] Agent 4 (HJK) & Agent 5 (YRK)\n",
        "\n",
        "class PatchTSTCore(nn.Module):\n",
        "    def __init__(self, l=60): super().__init__(); self.l=nn.Linear(l,1)\n",
        "    def forward(self, x): return self.l(x.permute(0,2,1)).squeeze(-1)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Agent 4: HJK (Executioner)\n",
        "# íŠ¹ì§•: PPO í–‰ë™ ëª¨ì‚¬ -> í™•ì‹¤í•  ë•Œë§Œ ë§¤ìˆ˜, ì•„ë‹ˆë©´ í˜„ê¸ˆ(0) ë¦¬í„´\n",
        "# ---------------------------------------------------------\n",
        "class Agent_HJK:\n",
        "    def __init__(self, n):\n",
        "        self.m = PatchTSTCore().to(device)\n",
        "    def train(self, c, v): pass\n",
        "    def trade(self, c, v):\n",
        "        if len(c) < 60: return np.zeros(10) # ë°ì´í„° ì—†ìœ¼ë©´ í˜„ê¸ˆ ë³´ìœ \n",
        "\n",
        "        # ì˜ˆì¸¡\n",
        "        inp = torch.FloatTensor(c.pct_change().fillna(0).iloc[-60:].values).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            pred_ret = self.m(inp).cpu().numpy()[0]\n",
        "\n",
        "        # [Action Logic]\n",
        "        # ê°•í™”í•™ìŠµì˜ 'ê´€ë§' ì•¡ì…˜ì„ ëª¨ì‚¬: ì˜ˆì¸¡ ìˆ˜ìµë¥ ì´ 0.2% ë¯¸ë§Œì´ë©´ ë§¤ìˆ˜ ì•ˆ í•¨\n",
        "        buy_threshold = 0.002\n",
        "        actions = pred_ret > buy_threshold\n",
        "\n",
        "        if np.sum(actions) == 0:\n",
        "            return np.zeros(10) # ì „ì•¡ í˜„ê¸ˆ ë³´ìœ  (ë¹„ì¤‘ 0)\n",
        "\n",
        "        # ë§¤ìˆ˜í•  ì¢…ëª©ì— ëŒ€í•´ì„œë§Œ ë¹„ì¤‘ ë°°ë¶„ (Kelly Criterion ê°„ì†Œí™”)\n",
        "        w = np.zeros(10)\n",
        "        w[actions] = pred_ret[actions]\n",
        "        return w / np.sum(w)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Agent 5: YRK (Prudent Analyst)\n",
        "# íŠ¹ì§•: Multi-Horizon ëª¨ì‚¬ + Confidence(í™•ì‹ ) ê¸°ë°˜ ê°€ì¤‘ì¹˜\n",
        "# ---------------------------------------------------------\n",
        "class Agent_YRK:\n",
        "    def __init__(self, n):\n",
        "        self.m = iTransformerCore(n).to(device)\n",
        "    def train(self, c, v): pass\n",
        "    def trade(self, c, v):\n",
        "        if len(c) < 60: return np.ones(10)/10\n",
        "\n",
        "        # 1. ì˜ˆì¸¡\n",
        "        inp = torch.FloatTensor(c.pct_change().fillna(0).iloc[-60:].values).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            pred_1d = self.m(inp).cpu().numpy()[0]\n",
        "\n",
        "        # 2. Confidence(ì‹ ë¢°ë„) ê³„ì‚°\n",
        "        # ì›ë³¸ ë¡œì§: \"ì˜ˆì¸¡ê°’ì´ ìµœê·¼ ë³€ë™ì„±ë³´ë‹¤ ì›”ë“±íˆ ë†’ì•„ì•¼ í™•ì‹ í•œë‹¤\"\n",
        "        recent_vol = c.pct_change().iloc[-20:].std().values + 1e-6\n",
        "        confidence = np.abs(pred_1d) / recent_vol # Sharp Ratioì™€ ìœ ì‚¬\n",
        "\n",
        "        # ì‹ ë¢°ë„ê°€ ë‚®ì€ ì¢…ëª©ì€ ê³¼ê°íˆ ë²„ë¦¼ (Masking)\n",
        "        conf_threshold = 0.5\n",
        "        valid_mask = confidence > conf_threshold\n",
        "\n",
        "        if np.sum(valid_mask) == 0:\n",
        "            return np.ones(10)/10 # í™•ì‹  ì—†ìœ¼ë©´ ë¶„ì‚° íˆ¬ì\n",
        "\n",
        "        w = np.zeros(10)\n",
        "        w[valid_mask] = confidence[valid_mask] # ì‹ ë¢°ë„ ë¹„ë¡€ ë°°ë¶„\n",
        "        return w / np.sum(w)"
      ],
      "metadata": {
        "id": "32dJh7F23v5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [Cell 6] ë©”ì¸ ì‹¤í–‰ (Ensemble 5.0)\n",
        "def run_ensemble_final():\n",
        "    print(\"ğŸš€ [System 5.0] 'Smart-Aggressive' Ensemble Started...\")\n",
        "    print(\"ğŸ‘‰ ì „ëµ: 200ì¼ ì´í‰ì„  ìœ„ì—ì„œëŠ” 'í’€ë§¤ìˆ˜', ê¹¨ì§€ë©´ 'ë°©ì–´ ëª¨ë“œ' ê°€ë™\")\n",
        "\n",
        "    # 1. ë°ì´í„° ë¡œë“œ\n",
        "    close_df, vol_df = load_local_files()\n",
        "    if close_df is None: return\n",
        "    qqq_data = load_smart_qqq(close_df.index)\n",
        "    if qqq_data is None:\n",
        "        qqq_data = close_df.mean(axis=1)\n",
        "    if isinstance(qqq_data, pd.DataFrame): qqq_data = qqq_data.iloc[:, 0]\n",
        "\n",
        "    # [New] ì‹œì¥ ì¶”ì„¸ì„  ê³„ì‚° (200ì¼ ì´ë™í‰ê· )\n",
        "    qqq_ma200 = qqq_data.rolling(window=200).mean()\n",
        "\n",
        "    # 2. íŒ€ì¥ í•™ìŠµ\n",
        "    gating_model, label_encoder, num_vars = train_itransformer_leader()\n",
        "    if gating_model is None: return\n",
        "\n",
        "    agents = { 'JJH': Agent_JJH(10), 'JHP': Agent_JHP(10), 'IHK': Agent_IHK(10), 'HJK': Agent_HJK(10), 'YRK': Agent_YRK(10) }\n",
        "\n",
        "    print(\"\\nğŸ”¥ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘...\")\n",
        "    full_dates = close_df.index\n",
        "    try: test_start_idx = full_dates.searchsorted(pd.Timestamp(Config.TEST_START))\n",
        "    except: test_start_idx = int(len(full_dates) * 0.8)\n",
        "\n",
        "    sim_start_idx = max(200, test_start_idx - 20) # MA200 ê³„ì‚°ì„ ìœ„í•´ ì—¬ìœ  í™•ë³´\n",
        "    simulation_dates = full_dates[sim_start_idx:]\n",
        "\n",
        "    balance = Config.INITIAL_CAPITAL\n",
        "    history, context_buffer = [], []\n",
        "    le_classes = label_encoder.classes_\n",
        "    idx_to_model = {i: name for i, name in enumerate(le_classes)}\n",
        "\n",
        "    for i in tqdm(range(len(simulation_dates)-1)):\n",
        "        curr_date = simulation_dates[i]\n",
        "        is_test = curr_date >= pd.Timestamp(Config.TEST_START)\n",
        "\n",
        "        # [Step 1] íŒ€ì¥\n",
        "        weights_map = {name: 0.0 for name in Config.MODEL_ORDER}\n",
        "        if len(context_buffer) >= Config.LOOKBACK:\n",
        "            ctx = np.array(context_buffer[-Config.LOOKBACK:], dtype=np.float32)\n",
        "            inp = torch.FloatTensor(ctx).unsqueeze(0).to(device)\n",
        "            with torch.no_grad(): raw_w = gating_model(inp).cpu().numpy()[0]\n",
        "            for idx, w in enumerate(raw_w): weights_map[idx_to_model[idx]] = w\n",
        "        else:\n",
        "            for m in Config.MODEL_ORDER: weights_map[m] = 0.2\n",
        "\n",
        "        # [Step 2] ì—ì´ì „íŠ¸ ìˆ˜í–‰\n",
        "        c_hist = close_df.loc[:curr_date]\n",
        "        v_hist = vol_df.loc[:curr_date]\n",
        "\n",
        "        final_w = np.zeros(10)\n",
        "        daily_rets = {}\n",
        "\n",
        "        p_curr = close_df.loc[curr_date]\n",
        "        p_next = close_df.loc[simulation_dates[i+1]]\n",
        "        day_ret = (p_next - p_curr) / p_curr\n",
        "\n",
        "        for m_name in Config.MODEL_ORDER:\n",
        "            try:\n",
        "                w_agent = agents[m_name].trade(c_hist, v_hist)\n",
        "                w_leader = weights_map[m_name]\n",
        "                final_w += w_agent * w_leader\n",
        "\n",
        "                ret_val = np.sum(day_ret * w_agent)\n",
        "                if isinstance(ret_val, (np.ndarray, pd.Series)): ret_val = ret_val.item()\n",
        "                daily_rets[m_name] = float(ret_val)\n",
        "            except: daily_rets[m_name] = 0.0\n",
        "\n",
        "        # [Step 3] ìµœì¢… ìˆ˜ìµë¥  (Circuit Breaker ì ìš©)\n",
        "        if is_test:\n",
        "            # --- [í•µì‹¬ ë¡œì§] ì‹œì¥ ìƒí™© íŒë‹¨ ---\n",
        "            current_qqq = qqq_data.loc[curr_date]\n",
        "            current_ma200 = qqq_ma200.loc[curr_date]\n",
        "\n",
        "            # MA200 ë°ì´í„°ê°€ ì—†ê±°ë‚˜, ê°€ê²©ì´ MA200 ìœ„ì— ìˆìœ¼ë©´ -> Bull Market\n",
        "            is_bull_market = np.isnan(current_ma200) or (current_qqq >= current_ma200)\n",
        "\n",
        "            if is_bull_market:\n",
        "                # [ìƒìŠ¹ì¥] ê°•ì œ í’€ë§¤ìˆ˜ (Exposure 1.0)\n",
        "                # ì—ì´ì „íŠ¸ë“¤ì´ ì«„ì•„ì„œ í˜„ê¸ˆ ë‚¨ê²¨ë„ ê°•ì œë¡œ ì£¼ì‹ ì‚¬ê²Œ í•¨\n",
        "                if np.sum(final_w) > 0:\n",
        "                    final_w = final_w / np.sum(final_w)\n",
        "                else:\n",
        "                    # ë§Œì•½ ì „ì› ë§¤ìˆ˜ ê±°ë¶€ ì‹œ, QQQ(ë²¤ì¹˜ë§ˆí¬) ì¶”ì¢… or í˜„ê¸ˆ\n",
        "                    # ì—¬ê¸°ì„  ìƒìŠ¹ì¥ì´ë¯€ë¡œ ì´ì „ í¬íŠ¸í´ë¦¬ì˜¤ ìœ ì§€ or 1/N ë“± ì „ëµ í•„ìš”\n",
        "                    # ì‹¬í”Œí•˜ê²Œ: IHK(ë°©ì–´í˜•)ì—ê²Œ ê°•ì œ ìœ„ì„\n",
        "                    final_w = np.ones(10)/10\n",
        "            else:\n",
        "                # [í•˜ë½ì¥] í˜„ê¸ˆ í—ˆìš© (Exposure < 1.0 ê°€ëŠ¥)\n",
        "                # HJKë‚˜ YRKê°€ í˜„ê¸ˆ ë“¤ìê³  í•˜ë©´ ê·¸ ë§ì„ ë“¤ì–´ì¤Œ (Normalize ì•ˆ í•¨)\n",
        "                pass\n",
        "\n",
        "            # ìµœì¢… íˆ¬ì ì§‘í–‰\n",
        "            port_ret = np.sum(day_ret * final_w)\n",
        "            balance *= (1 + port_ret)\n",
        "\n",
        "            # ê¸°ë¡ (Exposure í™•ì¸ìš©)\n",
        "            total_exposure = float(np.sum(final_w))\n",
        "            history.append({\n",
        "                'Date': curr_date,\n",
        "                'Value': float(balance),\n",
        "                'Exposure': total_exposure,\n",
        "                'Regime': 1.0 if is_bull_market else 0.0 # 1=Bull, 0=Bear\n",
        "            })\n",
        "\n",
        "        # ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘\n",
        "        if len(qqq_data.loc[:curr_date]) > 60:\n",
        "            q_h = qqq_data.loc[:curr_date]\n",
        "            try:\n",
        "                feat = [\n",
        "                    float((q_h.iloc[-1]/q_h.rolling(20).mean().iloc[-1]-1)),\n",
        "                    float(q_h.pct_change().iloc[-5:].std()),\n",
        "                    float((q_h.iloc[-1]/q_h.iloc[-60]-1))\n",
        "                ]\n",
        "            except: feat = [0.0, 0.0, 0.0]\n",
        "            for m in Config.MODEL_ORDER: feat.append(float(daily_rets.get(m, 0.0)))\n",
        "            context_buffer.append(feat)\n",
        "\n",
        "    if not history: print(\"âŒ ê²°ê³¼ ë°ì´í„° ì—†ìŒ\"); return\n",
        "    res_df = pd.DataFrame(history).set_index('Date')\n",
        "\n",
        "    q_test = qqq_data.loc[res_df.index]\n",
        "    if len(q_test) > 0: q_curve = (q_test / q_test.iloc[0]) * Config.INITIAL_CAPITAL\n",
        "    else: q_curve = pd.Series([Config.INITIAL_CAPITAL]*len(res_df), index=res_df.index)\n",
        "\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    # 1. ìˆ˜ìµë¥ \n",
        "    plt.subplot(3,1,1)\n",
        "    plt.plot(res_df['Value'], label='Ensemble 5.0 (Smart Exposure)', color='#d62728', linewidth=2)\n",
        "    plt.plot(q_curve, label='QQQ Benchmark', color='gray', linestyle='--')\n",
        "    plt.title(f\"Final Balance: ${balance:,.0f}\")\n",
        "    plt.legend(); plt.grid(alpha=0.3)\n",
        "\n",
        "    # 2. Exposure ë³€í™”\n",
        "    plt.subplot(3,1,2)\n",
        "    plt.plot(res_df['Exposure'], label='Stock Weight (0.0 ~ 1.0)', color='blue')\n",
        "    plt.title(\"Active Exposure Control\")\n",
        "    plt.legend(); plt.grid(alpha=0.3)\n",
        "\n",
        "    # 3. ì‹œì¥ êµ­ë©´ (Bull vs Bear)\n",
        "    plt.subplot(3,1,3)\n",
        "    plt.plot(res_df['Regime'], label='Market Regime (1=Bull, 0=Bear)', color='green', alpha=0.5)\n",
        "    plt.fill_between(res_df.index, res_df['Regime'], color='green', alpha=0.1)\n",
        "    plt.title(\"Detected Market Regime (MA200)\")\n",
        "    plt.legend(); plt.grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_ensemble_final()"
      ],
      "metadata": {
        "id": "HtMA37K07soP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (ë²ˆì™¸) íŒ€ì›ë“¤ ë¡œì§ ë­‰ê°œë†“ì€ ì´ˆê¸°ë²„ì „ ensemble - ë¯¸ìŠ¤í„°ë¦¬í•˜ê²Œ ìˆ˜ìµë¥ ì€ ì¢‹ìŒ\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import yfinance as yf\n",
        "from tqdm.auto import tqdm\n",
        "import warnings\n",
        "import random\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# =========================================================\n",
        "# âš™ï¸ ì„¤ì •\n",
        "# =========================================================\n",
        "class Config:\n",
        "    STOCKS = ['META', 'TSLA', 'NFLX', 'NVDA', 'PLTR', 'MSFT', 'GOOG', 'AAPL', 'AVGO', 'AMZN']\n",
        "    MODEL_ORDER = ['JJH', 'JHP', 'IHK', 'HJK', 'YRK'] # ìˆœì„œ ê³ ì •\n",
        "\n",
        "    START_DATE = '2020-11-02'\n",
        "    TRAIN_END = '2023-12-31'\n",
        "    TEST_START = '2024-01-01'\n",
        "    END_DATE = '2025-10-31'\n",
        "    INITIAL_CAPITAL = 10000.0\n",
        "    META_DATA_PATH = 'meta_training_data_v2.csv'\n",
        "    LOOKBACK = 20\n",
        "\n",
        "def set_all_seeds(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "set_all_seeds()\n",
        "\n",
        "# =========================================================\n",
        "# ğŸ› ï¸ 1. ìŠ¤ë§ˆíŠ¸ ë°ì´í„° ë¡œë”\n",
        "# =========================================================\n",
        "def load_local_files():\n",
        "    print(\"ğŸ“‚ [Smart Loader] ë°ì´í„° ë¡œë“œ ë° ì •ë ¬ ì¤‘...\")\n",
        "    search_dir = '/content' if os.path.exists('/content') else '.'\n",
        "    all_files = [f for f in os.listdir(search_dir) if f.endswith('.csv')]\n",
        "\n",
        "    close_dict, volume_dict = {}, {}\n",
        "    loaded_count = 0\n",
        "\n",
        "    for s in Config.STOCKS:\n",
        "        target = next((os.path.join(search_dir, f) for f in all_files if s.upper() in f.upper()), None)\n",
        "        if not target: continue\n",
        "        try:\n",
        "            df = pd.read_csv(target)\n",
        "            df.columns = df.columns.str.strip()\n",
        "\n",
        "            # ë‚ ì§œ ì²˜ë¦¬\n",
        "            if 'Date' in df.columns: df['Date'] = pd.to_datetime(df['Date'])\n",
        "            else: df.rename(columns={df.columns[0]: 'Date'}, inplace=True); df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "            # ì •ë ¬\n",
        "            df = df.set_index('Date').sort_index()\n",
        "            df = df[~df.index.duplicated(keep='last')]\n",
        "\n",
        "            # Close ì¶”ì¶œ\n",
        "            c_col = next((c for c in df.columns if 'close' in c.lower() or 'last' in c.lower()), None)\n",
        "            if c_col:\n",
        "                val = df[c_col].astype(str).str.replace(r'[$,]', '', regex=True).astype(float) if df[c_col].dtype==object else df[c_col]\n",
        "                close_dict[s] = val\n",
        "\n",
        "            # Volume ì¶”ì¶œ\n",
        "            v_col = next((c for c in df.columns if 'vol' in c.lower()), None)\n",
        "            if v_col:\n",
        "                val = df[v_col].astype(str).str.replace(r'[$,]', '', regex=True).astype(float) if df[v_col].dtype==object else df[v_col]\n",
        "                volume_dict[s] = val\n",
        "\n",
        "            loaded_count += 1\n",
        "        except: pass\n",
        "\n",
        "    if not close_dict: return None, None\n",
        "\n",
        "    c_df = pd.DataFrame(close_dict).fillna(method='ffill').fillna(method='bfill')\n",
        "    v_df = pd.DataFrame(volume_dict).fillna(0)\n",
        "\n",
        "    # Volume shape ê°•ì œ ë§ì¶¤\n",
        "    v_df = v_df.reindex(index=c_df.index, columns=c_df.columns).fillna(0)\n",
        "\n",
        "    mask = (c_df.index >= Config.START_DATE) & (c_df.index <= Config.END_DATE)\n",
        "    print(f\"âœ… {loaded_count}ê°œ ì¢…ëª© ë¡œë“œ ì™„ë£Œ\")\n",
        "\n",
        "    return c_df.loc[mask], v_df.loc[mask]\n",
        "\n",
        "def load_smart_qqq(target_index):\n",
        "    print(\"ğŸ” QQQ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° í™•ë³´ ì¤‘...\")\n",
        "    qqq_series = None\n",
        "    search_dir = '/content' if os.path.exists('/content') else '.'\n",
        "    f_path = next((os.path.join(search_dir, f) for f in os.listdir(search_dir) if 'QQQ' in f.upper() and f.endswith('.csv')), None)\n",
        "\n",
        "    if f_path:\n",
        "        try:\n",
        "            df = pd.read_csv(f_path)\n",
        "            if 'Date' not in df.columns: df.rename(columns={df.columns[0]:'Date'}, inplace=True)\n",
        "            df['Date'] = pd.to_datetime(df['Date'])\n",
        "            df = df.set_index('Date').sort_index()\n",
        "            c = next((c for c in df.columns if 'close' in c.lower()), None)\n",
        "            if c: qqq_series = df[c].astype(str).str.replace(r'[$,]','',regex=True).astype(float) if df[c].dtype==object else df[c]\n",
        "        except: pass\n",
        "\n",
        "    if qqq_series is None:\n",
        "        try:\n",
        "            q = yf.download('QQQ', start=Config.START_DATE, end=Config.END_DATE, progress=False)\n",
        "            if not q.empty: qqq_series = q['Close'] if isinstance(q['Close'], pd.Series) else q['Close'].iloc[:,0]\n",
        "        except: pass\n",
        "\n",
        "    if qqq_series is None:\n",
        "        print(\"  âš ï¸ QQQ ë°ì´í„° ì—†ìŒ -> í•©ì„± ì§€ìˆ˜ ìƒì„±\")\n",
        "        return None\n",
        "\n",
        "    return qqq_series.reindex(target_index, method='ffill').fillna(method='bfill')\n",
        "\n",
        "# =========================================================\n",
        "# ğŸ§  2. íŒ€ì¥ AI & ë°ì´í„°ì…‹\n",
        "# =========================================================\n",
        "class MetaWindowDataset(Dataset):\n",
        "    def __init__(self, df, lookback=20, le=None):\n",
        "        self.lookback = lookback\n",
        "        feature_cols = ['Feature_GapMA20', 'Feature_Vol5D', 'Feature_Mom60D']\n",
        "        model_ret_cols = [f'Ret_{m}' for m in Config.MODEL_ORDER]\n",
        "\n",
        "        final_cols = feature_cols + model_ret_cols\n",
        "        missing = [c for c in final_cols if c not in df.columns]\n",
        "        if missing: raise ValueError(f\"CSV ì»¬ëŸ¼ ë¶€ì¡±: {missing}\")\n",
        "\n",
        "        self.features = df[final_cols].values\n",
        "        self.num_vars = len(final_cols)\n",
        "\n",
        "        if le is None:\n",
        "            self.le = LabelEncoder()\n",
        "            self.labels = self.le.fit_transform(df['Label_Best_Model'])\n",
        "        else:\n",
        "            self.le = le\n",
        "            self.labels = self.le.transform(df['Label_Best_Model'])\n",
        "\n",
        "    def __len__(self): return len(self.features) - self.lookback\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.features[idx : idx + self.lookback]\n",
        "        y = self.labels[idx + self.lookback]\n",
        "        return torch.FloatTensor(x), torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "class iTransformerGating(nn.Module):\n",
        "    def __init__(self, num_variates, lookback_len=20, d_model=64, num_classes=5):\n",
        "        super(iTransformerGating, self).__init__()\n",
        "        self.enc_embedding = nn.Linear(lookback_len, d_model)\n",
        "        self.encoder = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model, 4, batch_first=True, dropout=0.1), 2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.proj = nn.Linear(num_variates * d_model, num_classes)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        return self.softmax(self.proj(self.flatten(self.encoder(self.enc_embedding(x)))))\n",
        "\n",
        "def train_itransformer_leader():\n",
        "    print(\"ğŸ§  [iTransformer] íŒ€ì¥ AI í•™ìŠµ ì‹œì‘...\")\n",
        "    path = Config.META_DATA_PATH\n",
        "    if not os.path.exists(path):\n",
        "        if os.path.exists('/content/'+path): path = '/content/'+path\n",
        "        else: print(f\"âŒ '{path}' íŒŒì¼ ì—†ìŒ.\"); return None, None, None\n",
        "\n",
        "    df = pd.read_csv(path)\n",
        "    dataset = MetaWindowDataset(df, lookback=Config.LOOKBACK)\n",
        "    loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "    model = iTransformerGating(dataset.num_vars, Config.LOOKBACK, 64, len(dataset.le.classes_)).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    model.train()\n",
        "    for _ in range(100):\n",
        "        for bx, by in loader:\n",
        "            optimizer.zero_grad()\n",
        "            nn.CrossEntropyLoss()(model(bx.to(device)), by.to(device)).backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    print(\"âœ… íŒ€ì¥ í•™ìŠµ ì™„ë£Œ.\")\n",
        "    return model, dataset.le, dataset.num_vars\n",
        "\n",
        "# =========================================================\n",
        "# ğŸ§  3. íŒ€ì› AI (Agents)\n",
        "# =========================================================\n",
        "class iTransformerCore(nn.Module):\n",
        "    def __init__(self, n, l=60, d=64):\n",
        "        super().__init__(); self.e=nn.Linear(l,d); self.t=nn.TransformerEncoder(nn.TransformerEncoderLayer(d,4,batch_first=True,dropout=0.1),2); self.p=nn.Linear(d,1)\n",
        "    def forward(self, x): return self.p(self.t(self.e(x.permute(0,2,1)))).squeeze(-1)\n",
        "\n",
        "class PatchTSTCore(nn.Module):\n",
        "    def __init__(self, l=60): super().__init__(); self.l=nn.Linear(l,1)\n",
        "    def forward(self, x): return self.l(x.permute(0,2,1)).squeeze(-1)\n",
        "\n",
        "class QuantformerCore(nn.Module):\n",
        "    def __init__(self, i=2, d=32): super().__init__(); self.e=nn.Linear(i,d); self.t=nn.TransformerEncoder(nn.TransformerEncoderLayer(d,4,batch_first=True,dropout=0.1),2); self.f=nn.Linear(d,3)\n",
        "    def forward(self, x): return nn.Softmax(dim=-1)(self.f(self.t(self.e(x))[:,-1,:]))\n",
        "\n",
        "class Agent_JJH:\n",
        "    def __init__(self, n): self.m=iTransformerCore(n).to(device); self.o=optim.Adam(self.m.parameters(), lr=1e-3)\n",
        "    def train(self, c, v):\n",
        "        d=c.pct_change().fillna(0).values; X,y=[],[]\n",
        "        for i in range(len(d)-60): X.append(d[i:i+60]); y.append(d[i+60])\n",
        "        Xt,yt=torch.FloatTensor(np.array(X)).to(device),torch.FloatTensor(np.array(y)).to(device)\n",
        "        self.m.train();\n",
        "        for _ in range(5): self.o.zero_grad(); nn.MSELoss()(self.m(Xt),yt).backward(); self.o.step()\n",
        "    def trade(self, c, v):\n",
        "        self.m.eval(); inp=torch.FloatTensor(c.pct_change().fillna(0).values).unsqueeze(0).to(device)\n",
        "        with torch.no_grad(): s=self.m(inp).cpu().numpy()[0]\n",
        "        w=np.zeros(len(s)); w[np.argsort(s)[-3:]]=1/3; return w\n",
        "\n",
        "class Agent_JHP:\n",
        "    def __init__(self, n): self.m=QuantformerCore().to(device); self.o=optim.Adam(self.m.parameters(), lr=1e-3); self.s=Config.STOCKS\n",
        "    def train(self, c, v):\n",
        "        r,t=c.pct_change().fillna(0),v.pct_change().fillna(0); X,Y=[],[]\n",
        "        for s in self.s:\n",
        "            rv,tv=r[s].values,t[s].values\n",
        "            for i in range(len(rv)-20):\n",
        "                q=np.stack([rv[i:i+20],tv[i:i+20]],axis=1); n=(q-q.mean(0))/(q.std(0)+1e-8)\n",
        "                l=0 if rv[i+20]>0.005 else (2 if rv[i+20]<-0.005 else 1)\n",
        "                X.append(n); Y.append(l)\n",
        "        if not X: return\n",
        "        Xt,Yt=torch.FloatTensor(np.array(X)).to(device),torch.LongTensor(np.array(Y)).to(device)\n",
        "        if len(Xt)>3000: i=torch.randperm(len(Xt))[:3000]; Xt,Yt=Xt[i],Yt[i]\n",
        "        self.m.train();\n",
        "        for _ in range(5): self.o.zero_grad(); nn.CrossEntropyLoss()(self.m(Xt),Yt).backward(); self.o.step()\n",
        "    def trade(self, c, v):\n",
        "        self.m.eval(); r,t=c.pct_change().fillna(0).iloc[-20:],v.pct_change().fillna(0).iloc[-20:]; p=[]\n",
        "        for i in range(len(self.s)):\n",
        "            q=np.stack([r.iloc[:,i].values,t.iloc[:,i].values],axis=1); n=(q-q.mean(0))/(q.std(0)+1e-8)\n",
        "            with torch.no_grad(): p.append(self.m(torch.FloatTensor(n).unsqueeze(0).to(device))[0][0].item())\n",
        "        w=np.zeros(len(p)); w[np.argsort(p)[-3:]]=1/3; return w\n",
        "\n",
        "class Agent_IHK:\n",
        "    def __init__(self,n): pass\n",
        "    def train(self,c,v): pass\n",
        "    def trade(self,c,v): vol=c.pct_change().std().values+1e-6; i=1.0/vol; return i/np.sum(i)\n",
        "\n",
        "class Agent_HJK:\n",
        "    def __init__(self,n): self.m=PatchTSTCore().to(device); self.o=optim.Adam(self.m.parameters(),lr=1e-3)\n",
        "    def train(self,c,v):\n",
        "        d=c.pct_change().fillna(0).values; X,y=[],[]\n",
        "        for i in range(len(d)-60): X.append(d[i:i+60]); y.append(d[i+60])\n",
        "        self.m.train(); Xt,yt=torch.FloatTensor(np.array(X)).to(device),torch.FloatTensor(np.array(y)).to(device)\n",
        "        for _ in range(5): self.o.zero_grad(); nn.MSELoss()(self.m(Xt),yt).backward(); self.o.step()\n",
        "    def trade(self,c,v):\n",
        "        self.m.eval(); inp=torch.FloatTensor(c.pct_change().fillna(0).values).unsqueeze(0).to(device)\n",
        "        with torch.no_grad(): s=self.m(inp).cpu().numpy()[0]\n",
        "        w=np.zeros(len(s)); w[np.argsort(s)[-3:]]=1/3; return w\n",
        "\n",
        "class Agent_YRK:\n",
        "    def __init__(self,n): self.m=iTransformerCore(n).to(device); self.h=nn.Linear(n,n).to(device); self.o=optim.Adam(list(self.m.parameters())+list(self.h.parameters()),lr=1e-3)\n",
        "    def train(self,c,v):\n",
        "        d=c.pct_change().fillna(0).values; X,y=[],[]\n",
        "        for i in range(len(d)-60): X.append(d[i:i+60]); y.append(d[i+60])\n",
        "        Xt,yt=torch.FloatTensor(np.array(X)).to(device),torch.FloatTensor(np.array(y)).to(device)\n",
        "        self.m.train();\n",
        "        for _ in range(5): self.o.zero_grad(); nn.MSELoss()(self.h(self.m(Xt)),yt).backward(); self.o.step()\n",
        "    def trade(self,c,v):\n",
        "        self.m.eval(); inp=torch.FloatTensor(c.pct_change().fillna(0).values).unsqueeze(0).to(device)\n",
        "        with torch.no_grad(): s=self.m(inp); sc=(s+self.h(s)).cpu().numpy()[0]\n",
        "        w=np.zeros(len(sc)); w[np.argsort(sc)[-3:]]=1/3; return w\n",
        "\n",
        "# =========================================================\n",
        "# 4. ğŸ ì•™ìƒë¸” 2.0 ì‹¤í–‰ (Warm-up + Ordering + Holiday Fix)\n",
        "# =========================================================\n",
        "def run_ensemble_v2_final():\n",
        "    print(\"ğŸš€ [Win QQQ 2.0] Final System (Warm-up + Strict Ordering)...\")\n",
        "\n",
        "    close_df, vol_df = load_local_files()\n",
        "    if close_df is None: return\n",
        "    qqq_data = load_smart_qqq(close_df.index)\n",
        "    if qqq_data is None:\n",
        "        norm = close_df / close_df.iloc[0]; qqq_data = norm.mean(axis=1) * 100\n",
        "\n",
        "    gating_model, label_encoder, num_vars = train_itransformer_leader()\n",
        "    if gating_model is None: return\n",
        "\n",
        "    print(\"\\nğŸ‹ï¸ íŒ€ì›ë“¤ í•™ìŠµ ì¤‘...\")\n",
        "    train_c = close_df.loc[:Config.TRAIN_END]\n",
        "    train_v = vol_df.loc[:Config.TRAIN_END]\n",
        "    agents = { 'JJH': Agent_JJH(10), 'JHP': Agent_JHP(10), 'IHK': Agent_IHK(10), 'HJK': Agent_HJK(10), 'YRK': Agent_YRK(10) }\n",
        "    for name, agent in agents.items(): agent.train(train_c, train_v)\n",
        "\n",
        "    print(\"\\nğŸ”¥ Warm-up (ì˜ˆì—´) ì§„í–‰ ì¤‘...\")\n",
        "\n",
        "    full_dates = close_df.index\n",
        "\n",
        "    # [í•µì‹¬ ìˆ˜ì •] ë‚ ì§œê°€ ì •í™•íˆ ì¼ì¹˜í•˜ì§€ ì•Šì•„ë„ ê°€ì¥ ê°€ê¹Œìš´ ë‚ ì§œë¥¼ ì°¾ë„ë¡ searchsorted ì‚¬ìš©\n",
        "    # TEST_START('2024-01-01')ì´ ì—†ìœ¼ë©´ '2024-01-02'ì˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜í•¨\n",
        "    test_start_idx = full_dates.searchsorted(pd.Timestamp(Config.TEST_START))\n",
        "\n",
        "    # ì¸ë±ìŠ¤ ë²”ìœ„ ì²´í¬\n",
        "    if test_start_idx >= len(full_dates):\n",
        "        print(\"âŒ í…ŒìŠ¤íŠ¸ ê¸°ê°„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\"); return\n",
        "\n",
        "    warmup_start_idx = max(0, test_start_idx - 40)\n",
        "    simulation_dates = full_dates[warmup_start_idx:]\n",
        "\n",
        "    balance = Config.INITIAL_CAPITAL\n",
        "    history = []\n",
        "    context_buffer = []\n",
        "\n",
        "    le_classes = label_encoder.classes_\n",
        "    idx_to_model = {i: name for i, name in enumerate(le_classes)}\n",
        "\n",
        "    for i in tqdm(range(len(simulation_dates)-1)):\n",
        "        curr_date = simulation_dates[i]\n",
        "\n",
        "        # Test ê¸°ê°„ ì—¬ë¶€ í™•ì¸\n",
        "        is_test_period = curr_date >= pd.Timestamp(Config.TEST_START)\n",
        "\n",
        "        # --- [Step 1] ì‹œì¥ Feature ---\n",
        "        q_hist = qqq_data.loc[:curr_date]\n",
        "        if len(q_hist) < 60: continue\n",
        "\n",
        "        ma20 = q_hist.rolling(20).mean().iloc[-1]\n",
        "        gap_ma20 = (q_hist.iloc[-1] - ma20) / ma20 if ma20!=0 else 0\n",
        "        vol_5d = q_hist.pct_change().iloc[-5:].std()\n",
        "        mom_60d = (q_hist.iloc[-1]/q_hist.iloc[-60] - 1)\n",
        "\n",
        "        # --- [Step 2] íŒ€ì¥ì—ê²Œ ì§€ì‹œë°›ê¸° ---\n",
        "        weights_map = {name: 0.0 for name in Config.MODEL_ORDER}\n",
        "\n",
        "        if len(context_buffer) >= Config.LOOKBACK:\n",
        "            recent_ctx = np.array(context_buffer[-Config.LOOKBACK:])\n",
        "            inp_tensor = torch.FloatTensor(recent_ctx).unsqueeze(0).to(device)\n",
        "            with torch.no_grad():\n",
        "                raw_weights = gating_model(inp_tensor).cpu().numpy()[0]\n",
        "            for idx, w in enumerate(raw_weights):\n",
        "                weights_map[idx_to_model[idx]] = w\n",
        "        else:\n",
        "            for m in Config.MODEL_ORDER: weights_map[m] = 0.2\n",
        "\n",
        "        # --- [Step 3] í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± ---\n",
        "        c_win = close_df.loc[:curr_date].iloc[-60:]\n",
        "        v_win = vol_df.loc[:curr_date].iloc[-60:]\n",
        "\n",
        "        final_w = np.zeros(10)\n",
        "        daily_model_rets = {}\n",
        "\n",
        "        p_curr = close_df.loc[curr_date]\n",
        "        p_next = close_df.loc[simulation_dates[i+1]]\n",
        "        day_ret = (p_next - p_curr) / p_curr\n",
        "\n",
        "        for m_name in Config.MODEL_ORDER:\n",
        "            try:\n",
        "                w_agent = agents[m_name].trade(c_win, v_win)\n",
        "                w_leader = weights_map[m_name]\n",
        "                final_w += w_agent * w_leader\n",
        "                daily_model_rets[m_name] = np.sum(day_ret * w_agent)\n",
        "            except: daily_model_rets[m_name] = 0.0\n",
        "\n",
        "        if is_test_period:\n",
        "            port_ret = np.sum(day_ret * final_w)\n",
        "            balance *= (1 + port_ret)\n",
        "            history.append({'Date': curr_date, 'Value': balance})\n",
        "\n",
        "        current_features = [gap_ma20, vol_5d, mom_60d]\n",
        "        for m_name in Config.MODEL_ORDER:\n",
        "            current_features.append(daily_model_rets.get(m_name, 0.0))\n",
        "        context_buffer.append(current_features)\n",
        "\n",
        "    if not history: print(\"âŒ ê²°ê³¼ ì—†ìŒ\"); return\n",
        "    res_df = pd.DataFrame(history).set_index('Date')\n",
        "    common_idx = res_df.index.intersection(qqq_data.index)\n",
        "    qqq_curve = (qqq_data.loc[common_idx] / qqq_data.loc[common_idx[0]]) * Config.INITIAL_CAPITAL\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(res_df['Value'], label='Win QQQ 2.0 (Final)', color='#d62728', linewidth=2)\n",
        "    plt.plot(qqq_curve, label='QQQ Benchmark', color='black', linestyle='--', alpha=0.6)\n",
        "    plt.title(f\"Win QQQ 2.0 Result: ${balance:,.0f} (Return: {(balance-10000)/100:.1f}%)\")\n",
        "    plt.legend(); plt.grid(alpha=0.3); plt.show()\n",
        "    print(f\"ğŸ’° Final Balance: ${balance:,.0f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_ensemble_v2_final()"
      ],
      "metadata": {
        "id": "zFp--U8I5s3f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
