import torch
import torch.nn as nn
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
import random
import warnings
import yfinance as yf # ë²¤ì¹˜ë§ˆí¬(QQQ) ë‹¤ìš´ë¡œë“œìš©
from torch.utils.data import DataLoader, TensorDataset

warnings.filterwarnings('ignore')

# ---------------------------------------------------------
# 1. ì‹œë“œ ê³ ì • ë° í™˜ê²½ ì„¤ì •
# ---------------------------------------------------------
TARGET_SEED = 9
def set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    print(f"âœ… Seed fixed to {seed}.")

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
set_seed(TARGET_SEED)

# ---------------------------------------------------------
# 2. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ (Robust Loader)
# ---------------------------------------------------------
tickers = ['AAPL', 'NVDA', 'GOOG', 'META', 'TSLA', 'NFLX', 'PLTR', 'MSFT', 'AMZN', 'AVGO']

def preprocess_price(x):
    """ $ ê¸°í˜¸ ë° ì½¤ë§ˆ ì œê±° í›„ float ë³€í™˜ """
    if isinstance(x, str):
        return float(x.replace('$', '').replace(',', ''))
    return x

def load_and_clean_data(tickers):
    all_data = []
    print("ğŸ“‚ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì‹œì‘...")
    
    for ticker in tickers:
        # íŒŒì¼ ê²½ë¡œ íƒìƒ‰
        paths = [f"{ticker}.csv", f"/content/{ticker}.csv", f"{ticker.lower()}.csv", f"/content/{ticker.lower()}.csv"]
        filename = next((p for p in paths if os.path.exists(p)), None)
        
        if not filename:
            print(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {ticker} (Skip)")
            continue
        
        try:
            df = pd.read_csv(filename)
            df.columns = [c.strip() for c in df.columns] # ê³µë°± ì œê±°
            
            # ë‚ ì§œ ì²˜ë¦¬
            if 'Date' in df.columns:
                df['Date'] = pd.to_datetime(df['Date'])
                df.set_index('Date', inplace=True)
                df.sort_index(inplace=True) # [ì¤‘ìš”] ë‚ ì§œìˆœ ì •ë ¬
            
            # ê°€ê²© ë°ì´í„° ì „ì²˜ë¦¬ ($ ì œê±°)
            for col in df.columns:
                if df[col].dtype == 'object':
                    try: df[col] = df[col].apply(preprocess_price)
                    except: pass
            
            # ì»¬ëŸ¼ ë§¤í•‘
            close_col = next((c for c in df.columns if 'close' in c.lower()), None)
            vol_col = next((c for c in df.columns if 'volume' in c.lower()), None)
            
            if close_col:
                clean_df = pd.DataFrame(index=df.index)
                clean_df['Close'] = df[close_col].astype(float)
                clean_df['Return'] = clean_df['Close'].pct_change().fillna(0)
                
                # íšŒì „ìœ¨ (Volume ì—†ìœ¼ë©´ Returnìœ¼ë¡œ ëŒ€ì²´)
                if vol_col:
                    clean_df['Turnover'] = df[vol_col].astype(float).pct_change().fillna(0)
                else:
                    clean_df['Turnover'] = clean_df['Return']
                
                clean_df['Ticker'] = ticker
                # ë‹¤ìŒë‚  ìˆ˜ìµë¥  (íƒ€ê²Ÿ ë° ë°±í…ŒìŠ¤íŠ¸ìš©) - [ì¤‘ìš”] Shift(-1)
                clean_df['Next_Ret'] = clean_df['Return'].shift(-1)
                
                all_data.append(clean_df.dropna())
        except Exception as e:
            print(f"âŒ {ticker} ì—ëŸ¬: {e}")

    if not all_data:
        raise ValueError("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    return pd.concat(all_data).sort_index()

full_df = load_and_clean_data(tickers)

# ---------------------------------------------------------
# 3. ë°ì´í„° ë¶„í•  (Time-Series Split) - [í”¼ë“œë°± ë°˜ì˜]
# ---------------------------------------------------------
# ì „ì²´ ê¸°ê°„ì˜ 60%ë¥¼ í•™ìŠµ, ë‚˜ë¨¸ì§€ 40%ë¥¼ í…ŒìŠ¤íŠ¸ë¡œ ì‚¬ìš© (ì„ì§€ ì•ŠìŒ)
dates = full_df.index.unique().sort_values()
split_idx = int(len(dates) * 0.6)
split_date = dates[split_idx]

print(f"ğŸ“… ë°ì´í„° ë¶„í•  ê¸°ì¤€ì¼: {split_date.date()}")
print(f"   - í•™ìŠµ ê¸°ê°„: ~ {split_date.date()}")
print(f"   - í…ŒìŠ¤íŠ¸ ê¸°ê°„: {split_date.date()} ~")

train_df = full_df[full_df.index < split_date]
test_df = full_df[full_df.index >= split_date]

# ---------------------------------------------------------
# 4. ë°ì´í„°ì…‹ ìƒì„± (Quantformer Format)
# ---------------------------------------------------------
def create_sequences(df, lookback=20):
    X_list, Y_list = [], []
    meta_list = [] # ë°±í…ŒìŠ¤íŠ¸ìš© ë©”íƒ€ë°ì´í„° (ë‚ ì§œ, í‹°ì»¤, ì‹¤ì œìˆ˜ìµë¥ )
    
    grouped = df.groupby('Ticker')
    
    for ticker, group in grouped:
        values = group[['Return', 'Turnover']].values
        next_rets = group['Next_Ret'].values
        dates = group.index
        
        for i in range(len(values) - lookback):
            seq = values[i : i+lookback]
            
            # Z-score Normalization
            mean = seq.mean(axis=0)
            std = seq.std(axis=0) + 1e-8
            seq_norm = (seq - mean) / std
            
            # Target: ë‹¤ìŒë‚  ìˆ˜ìµë¥  ë¶„ë¥˜ (ìƒìœ„ 33% Bull, í•˜ìœ„ 33% Bear)
            # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ì ˆëŒ€ìˆ˜ìµë¥  ê¸°ì¤€ (0.5% ì´ìƒ ìƒìŠ¹ ì‹œ Bull)
            n_ret = next_rets[i+lookback-1]
            if n_ret > 0.005: label = 0 # Bull
            elif n_ret < -0.005: label = 2 # Bear
            else: label = 1 # Neutral
            
            X_list.append(seq_norm)
            Y_list.append(label)
            # [ì¤‘ìš”] ë°±í…ŒìŠ¤íŒ…ì„ ìœ„í•´ ì‹¤ì œ ë‹¤ìŒë‚  ìˆ˜ìµë¥  ì €ì¥
            meta_list.append({
                'Date': dates[i+lookback-1],
                'Ticker': ticker,
                'Actual_Ret': n_ret
            })

    X = torch.tensor(np.array(X_list), dtype=torch.float32)
    Y = torch.tensor(np.array(Y_list), dtype=torch.long)
    return X, Y, meta_list

train_X, train_Y, _ = create_sequences(train_df)
test_X, test_Y, test_meta = create_sequences(test_df)

print(f"âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: Train({len(train_X)}), Test({len(test_X)})")

# ---------------------------------------------------------
# 5. Quantformer ëª¨ë¸ (ìˆ˜ì • ì—†ìŒ)
# ---------------------------------------------------------
class Quantformer(nn.Module):
    def __init__(self, input_dim=2, d_model=32, nhead=4, num_layers=2):
        super(Quantformer, self).__init__()
        self.embedding = nn.Linear(input_dim, d_model)
        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True, dropout=0.1)
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        self.fc_out = nn.Linear(d_model, 3) # Bull, Neutral, Bear
        self.softmax = nn.Softmax(dim=-1)

    def forward(self, x):
        x = self.embedding(x)
        x = self.transformer(x)
        return self.softmax(self.fc_out(x[:, -1, :]))

# ---------------------------------------------------------
# 6. í•™ìŠµ (Training)
# ---------------------------------------------------------
model = Quantformer().to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

print("ğŸš€ í•™ìŠµ ì‹œì‘...")
model.train()
train_loader = DataLoader(TensorDataset(train_X, train_Y), batch_size=64, shuffle=True)

for epoch in range(15):
    total_loss = 0
    for bx, by in train_loader:
        optimizer.zero_grad()
        pred = model(bx.to(device))
        loss = criterion(pred, by.to(device))
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    if (epoch+1) % 5 == 0:
        print(f"Epoch {epoch+1}/15 | Loss: {total_loss/len(train_loader):.4f}")

# ---------------------------------------------------------
# 7. ë°±í…ŒìŠ¤íŒ… (Real Backtest) - [í”¼ë“œë°± ë°˜ì˜]
# ---------------------------------------------------------
print("ğŸ“Š ë°±í…ŒìŠ¤íŒ… ì‹œì‘ (ì‹¤ì œ ìˆ˜ìµë¥  ê¸°ë°˜)...")

# 1. ëª¨ë¸ ì˜ˆì¸¡
model.eval()
with torch.no_grad():
    test_pred = model(test_X.to(device))
    bull_probs = test_pred[:, 0].cpu().numpy()

# 2. ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±
results_df = pd.DataFrame(test_meta)
results_df['Bull_Prob'] = bull_probs

# 3. ë‚ ì§œë³„ í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ê³„ì‚°
# ì „ëµ: ë§¤ì¼ Bull í™•ë¥ ì´ ê°€ì¥ ë†’ì€ ìƒìœ„ 3ê°œ ì¢…ëª© ë§¤ìˆ˜ (Equal Weight)
strategy_returns = []
dates_list = sorted(results_df['Date'].unique())

for d in dates_list:
    daily_data = results_df[results_df['Date'] == d]
    
    # ìƒìœ„ 3ê°œ ì„ ì •
    top_picks = daily_data.nlargest(3, 'Bull_Prob')
    
    # ìƒìœ„ ì¢…ëª©ë“¤ì˜ ì‹¤ì œ ë‹¤ìŒë‚  ìˆ˜ìµë¥  í‰ê· 
    daily_ret = top_picks['Actual_Ret'].mean()
    strategy_returns.append({'Date': d, 'Strategy_Ret': daily_ret})

strat_df = pd.DataFrame(strategy_returns).set_index('Date')
strat_df.index = pd.to_datetime(strat_df.index)

# 4. ë²¤ì¹˜ë§ˆí¬ (Real QQQ) ë‹¤ìš´ë¡œë“œ - [í”¼ë“œë°± ë°˜ì˜]
print("ğŸ“¥ QQQ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ë‹¤ìš´ë¡œë“œ...")
start_dt = strat_df.index[0]
end_dt = strat_df.index[-1] + pd.Timedelta(days=5) # ì—¬ìœ  ìˆê²Œ
qqq = yf.download('QQQ', start=start_dt, end=end_dt, progress=False)['Close']
# yfinance ë‹¤ìš´ë¡œë“œ ì‹œ Indexê°€ Datetimeì´ ì•„ë‹ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë³€í™˜
if not isinstance(qqq.index, pd.DatetimeIndex):
    qqq.index = pd.to_datetime(qqq.index)

# ìˆ˜ìµë¥  ê³„ì‚° ë° ì¸ë±ìŠ¤ ë§¤ì¹­
qqq_ret = qqq.pct_change().dropna()
comparison = pd.concat([strat_df, qqq_ret], axis=1).dropna()
comparison.columns = ['Strategy', 'QQQ']

# 5. ëˆ„ì  ìˆ˜ìµë¥  ê³„ì‚°
cum_ret = (1 + comparison).cumprod()

# ---------------------------------------------------------
# 8. ìµœì¢… ê²°ê³¼ ì‹œê°í™”
# ---------------------------------------------------------
plt.figure(figsize=(12, 6))
plt.plot(cum_ret['Strategy'], label='Quantformer (Top 3 Picks)', color='red', linewidth=2)
plt.plot(cum_ret['QQQ'], label='QQQ Benchmark (Real)', color='gray', linestyle='--')
plt.title(f"Win QQQ: Quantformer Backtest ({start_dt.date()} ~ {end_dt.date()})")
plt.ylabel("Cumulative Return (1.0 = Initial)")
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()

# ì„±ê³¼ ìš”ì•½
total_strat = cum_ret['Strategy'].iloc[-1] - 1
total_qqq = cum_ret['QQQ'].iloc[-1] - 1
print(f"\n[ìµœì¢… ì„±ê³¼ ìš”ì•½]")
print(f"ğŸ“ˆ ì „ëµ ìˆ˜ìµë¥ : {total_strat*100:.2f}%")
print(f"ğŸ“‰ QQQ ìˆ˜ìµë¥ : {total_qqq*100:.2f}%")
if total_strat > total_qqq:
    print(f"ğŸ† ê²°ê³¼: QQQ ìŠ¹ë¦¬! (ì´ˆê³¼ìˆ˜ìµ: {(total_strat-total_qqq)*100:.2f}%p)")
else:
    print(f"ğŸ¥€ ê²°ê³¼: QQQ íŒ¨ë°°...")
