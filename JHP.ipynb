=========================================================
# [Improved Ver] AI Strategy vs QQQ (Fixed by Auditor)
# =========================================================
import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import yfinance as yf
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
from torch.utils.data import DataLoader, TensorDataset
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
import random
import warnings

warnings.filterwarnings('ignore') # ë¶ˆí•„ìš”í•œ ê²½ê³  ë©”ì‹œì§€ ì°¨ë‹¨

# ì‹œë“œ ê³ ì •
TARGET_SEED = 9

def set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
    print(f"ğŸ”’ Seed fixed to {seed}.")

# --- ëª¨ë¸ ì•„í‚¤í…ì²˜ (ê¸°ì¡´ ìœ ì§€) ---
class MultiHeadAttention(nn.Module):
    def __init__(self, d_model, num_heads):
        super(MultiHeadAttention, self).__init__()
        self.num_heads = num_heads
        self.d_model = d_model
        self.depth = d_model // num_heads
        self.W_Q = nn.Linear(d_model, d_model)
        self.W_K = nn.Linear(d_model, d_model)
        self.W_V = nn.Linear(d_model, d_model)
        self.W_O = nn.Linear(d_model, d_model)
    def forward(self, Q, K, V):
        Q, K, V = self.W_Q(Q), self.W_K(K), self.W_V(V)
        Q = self._split_heads(Q)
        K = self._split_heads(K)
        V = self._split_heads(V)
        weights = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(self.depth)
        weights = torch.softmax(weights, dim=-1)
        return self.W_O(self._combine_heads(torch.matmul(weights, V)))
    def _split_heads(self, x): return x.view(x.size(0), -1, self.num_heads, self.depth).transpose(1, 2)
    def _combine_heads(self, x): return x.transpose(1, 2).contiguous().view(x.size(0), -1, self.num_heads * self.depth)

class Transformer(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_heads, num_layers, output_dim):
        super(Transformer, self).__init__()
        self.input_layer = nn.Linear(input_dim, hidden_dim)
        self.encoder_layers = nn.ModuleList([
            nn.Sequential(
                MultiHeadAttention(hidden_dim, num_heads),
                nn.LayerNorm(hidden_dim),
                nn.Sequential(nn.Linear(hidden_dim, 4*hidden_dim), nn.ReLU(), nn.Linear(4*hidden_dim, hidden_dim)),
                nn.LayerNorm(hidden_dim)
            ) for _ in range(num_layers)])
        self.output_layer = nn.Linear(hidden_dim, output_dim)
    def forward(self, x):
        x = self.input_layer(x)
        for layer in self.encoder_layers:
            attn = layer[0](x, x, x)
            x = layer[1](x + attn)
            ff = layer[2](x)
            x = layer[3](x + ff)
        return self.output_layer(x[:, -1, :]) # ë§ˆì§€ë§‰ ì‹œì ì˜ ì •ë³´ ì‚¬ìš©

# --- ë°ì´í„°ì…‹ ìƒì„± í•¨ìˆ˜ (ìˆ˜ì •ë¨: Rolling Window Scaling) ---
def create_rolling_dataset(data_values, lookback=60, input_size=30, horizon=1, stock_idx_start=3):
    X, y = [], []
    # ë°ì´í„°ê°€ ìœˆë„ìš°ë³´ë‹¤ ì‘ìœ¼ë©´ ë¹ˆ ë°°ì—´ ë°˜í™˜
    if len(data_values) <= lookback + horizon:
        return np.array([]), np.array([])
    
    # Sliding Window ë°©ì‹
    for i in range(len(data_values) - lookback - horizon):
        # 1. 60ì¼ì¹˜ ìœˆë„ìš° ì¶”ì¶œ (ì •ê·œí™” ê¸°ì¤€)
        window_raw = data_values[i : i + lookback]
        
        # 2. ìœˆë„ìš° ë‚´ë¶€ Min-Max Scaling (ì‹¤ì „ í™˜ê²½ê³¼ ë™ì¼í•˜ê²Œ ë§ì¶¤)
        w_min = np.min(window_raw, axis=0)
        w_max = np.max(window_raw, axis=0)
        # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€ (+1e-8)
        window_norm = (window_raw - w_min) / (w_max - w_min + 1e-8)
        
        # 3. ëª¨ë¸ ì…ë ¥: ì •ê·œí™”ëœ ìœˆë„ìš°ì˜ 'ë§ˆì§€ë§‰ 30ì¼' ì‚¬ìš©
        input_seq = window_norm[-input_size:]
        X.append(input_seq)
        
        # 4. ë¼ë²¨(Target): ë‹¤ìŒë‚  ìˆ˜ìµë¥  ê¸°ë°˜ ë­í‚¹
        # ìœˆë„ìš° ë°”ë¡œ ë‹¤ìŒ ë‚ ì˜ ì£¼ê°€ ë³€í™”ìœ¨ ê³„ì‚°
        curr_price = data_values[i + lookback - 1, stock_idx_start:]
        next_price = data_values[i + lookback + horizon - 1, stock_idx_start:]
        
        ret = (next_price - curr_price) / (curr_price + 1e-8)
        ret = np.nan_to_num(ret)
        
        # ìƒìœ„ 3ê°œ ì¢…ëª© Labeling (Hard Threshold)
        # ì£¼ì‹ ì¢…ëª© ê°œìˆ˜ë§Œí¼ ë­í‚¹ ë§¤ê¸°ê¸°
        num_stocks = data_values.shape[1] - stock_idx_start
        rank = np.argsort(np.argsort(ret))
        label = (rank >= (num_stocks - 3)).astype(float)
        y.append(label)
        
    return np.array(X), np.array(y)

# --- ì‹œë®¬ë ˆì´ì…˜ í•¨ìˆ˜ ---
def run_simulation_improved(seed_val):
    set_seed(seed_val)

    print("ğŸ“¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° í•™ìŠµ ì‹œì‘...")
    # [ìˆ˜ì •] COST ì œê±°, 10ì¢…ëª© ì¤€ìˆ˜
    stocks = ['AAPL', 'MSFT', 'NVDA', 'AMZN', 'META', 'AVGO', 'TSLA', 'GOOG', 'NFLX', 'PLTR']
    macros = ['^TNX', '^VIX', 'DX-Y.NYB']
    tickers = macros + stocks

    end_date = datetime.today()
    start_date = end_date - timedelta(days=365*8)

    # ë°ì´í„° ë‹¤ìš´ë¡œë“œ
    data_raw = yf.download(tickers, start=start_date, end=end_date, progress=False)
    if isinstance(data_raw.columns, pd.MultiIndex):
        closes = data_raw['Close']
    else:
        closes = data_raw['Close']
        
    closes = closes.fillna(method='ffill').fillna(method='bfill')
    
    # QQQ Benchmark
    qqq_raw = yf.download('QQQ', start=start_date, end=end_date, progress=False)
    if isinstance(qqq_raw.columns, pd.MultiIndex):
        qqq = qqq_raw['Close']['QQQ']
    else:
        qqq = qqq_raw['Close']
    
    # Train / Test Split
    test_start = end_date - timedelta(days=365*5)
    train_df = closes.loc[:test_start]
    
    print("ğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘ (Rolling Window Scaling ì ìš©)...")
    # í•™ìŠµ ë°ì´í„° ìƒì„± (í•™ìŠµ ë•Œë„ Rolling ì •ê·œí™” ì ìš©)
    train_values = train_df.values
    X_train, y_train = create_rolling_dataset(train_values, lookback=60, input_size=30, stock_idx_start=len(macros))
    
    inputs = torch.tensor(X_train, dtype=torch.float32)
    labels = torch.tensor(y_train, dtype=torch.float32)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # ëª¨ë¸ ì •ì˜
    model = Transformer(len(tickers), 128, 4, 2, len(stocks)).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.MSELoss()

    dataset = TensorDataset(inputs, labels)
    loader = DataLoader(dataset, batch_size=32, shuffle=True)

    # í•™ìŠµ
    print("ğŸ¤– ëª¨ë¸ í•™ìŠµ ì¤‘ (Epoch 10)...")
    model.train()
    for epoch in range(10):
        total_loss = 0
        for x, y in loader:
            x, y = x.to(device), y.to(device)
            optimizer.zero_grad()
            preds = model(x)
            loss = criterion(preds, y)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        # print(f"Epoch {epoch+1} Loss: {total_loss/len(loader):.4f}")
    print("âœ… í•™ìŠµ ì™„ë£Œ!")

    # --- ë°±í…ŒìŠ¤íŠ¸ ---
    initial_capital = 10000.0
    capital = initial_capital
    history = []
    dates = []
    selection_history = []

    current_date = test_start
    qqq_ma200 = qqq.rolling(window=200).mean()
    
    # ì¸ë±ìŠ¤ ì •ë¦¬
    qqq_bench = qqq.loc[test_start:end_date]
    try: base_price = qqq_bench.iloc[0].item()
    except: base_price = qqq_bench.iloc[0]
    qqq_norm = qqq_bench / base_price * 100

    print("ğŸš€ ë°±í…ŒìŠ¤íŒ… ì§„í–‰ ì¤‘...")
    while current_date < end_date:
        # ì›”ê°„ ë¦¬ë°¸ëŸ°ì‹± ë‚ ì§œ ê³„ì‚°
        next_date = current_date + relativedelta(months=1)
        if next_date > end_date: next_date = end_date
        str_curr = current_date.strftime('%Y-%m-%d')
        str_next = next_date.strftime('%Y-%m-%d')

        # 1. Market Filter (ì´ë™í‰ê· ì„  ì „ëµ ìœ ì§€)
        try:
            # ë‚ ì§œ ë§¤ì¹­ (ì£¼ë§/íœ´ì¼ ê³ ë ¤í•˜ì—¬ ê·¼ì‚¬ì¹˜ ì°¾ê¸°)
            curr_idx = qqq.index.get_indexer([current_date], method='pad')[0]
            curr_qqq = qqq.iloc[curr_idx]
            curr_ma200 = qqq_ma200.iloc[curr_idx]
            
            is_bull_market = curr_qqq > curr_ma200
        except Exception as e:
            is_bull_market = True # ë°ì´í„° ì—†ìœ¼ë©´ ì¼ë‹¨ ë§¤ìˆ˜

        if not is_bull_market:
            history.append(capital)
            dates.append(next_date)
            selection_history.append([next_date, "CASH", "CASH", "CASH"])
            current_date = next_date
            continue

        # 2. AI Selection
        try:
            train_slice = closes.loc[:str_curr]
            if len(train_slice) < 60:
                current_date = next_date
                continue
            
            # [ìˆ˜ì •] Inference ì‹œì—ë„ ë™ì¼í•œ ë¡œì§ ì ìš©
            # 60ì¼ì¹˜ ìœˆë„ìš° ê°€ì ¸ì˜¤ê¸°
            window = train_slice.iloc[-60:].values
            
            # ìœˆë„ìš° ìì²´ ì •ê·œí™” (í•™ìŠµê³¼ ë™ì¼)
            w_min = np.min(window, axis=0)
            w_max = np.max(window, axis=0)
            window_norm = (window - w_min) / (w_max - w_min + 1e-8)
            
            # ë§ˆì§€ë§‰ 30ì¼ì¹˜ë§Œ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©
            input_seq = window_norm[-30:]
            input_tensor = torch.tensor(input_seq, dtype=torch.float32).unsqueeze(0).to(device)
            
            model.eval()
            with torch.no_grad():
                scores = model(input_tensor).cpu().numpy()[0]
            
            # ì ìˆ˜ ê¸°ë°˜ ìƒìœ„ 3ê°œ ì„ ì •
            top_picks = pd.Series(scores, index=stocks).sort_values(ascending=False).head(3).index.tolist()
            selection_history.append([next_date] + top_picks)

            # ìˆ˜ìµë¥  ê³„ì‚°
            period_prices = closes.loc[str_curr:str_next, top_picks]
            if len(period_prices) > 0:
                # ë‹¨ìˆœ ìˆ˜ìµë¥  í‰ê· 
                period_return = (period_prices.iloc[-1] - period_prices.iloc[0]) / period_prices.iloc[0]
                avg_return = period_return.mean()
                capital = capital * (1 + avg_return)
        except Exception as e:
            print(f"Error at {str_curr}: {e}")
            pass

        history.append(capital)
        dates.append(next_date)
        current_date = next_date

    return history, dates, selection_history, stocks, qqq_norm

# --- ì‹œê°í™” í•¨ìˆ˜ (ê¸°ì¡´ ìœ ì§€) ---
def plot_final_results(history, dates, selection_history, stocks, qqq_norm):
    strategy_curve = pd.Series(history, index=dates)
    initial_val = history[0]
    final_val = history[-1]

    qqq_scaled = qqq_norm / 100 * initial_val
    try: qqq_final_val = qqq_scaled.iloc[-1].item()
    except: qqq_final_val = qqq_scaled.iloc[-1]

    ai_return_pct = (final_val - initial_val) / initial_val * 100
    qqq_return_pct = (qqq_final_val - initial_val) / initial_val * 100

    sel_df = pd.DataFrame(selection_history, columns=['Date', 'Pick1', 'Pick2', 'Pick3'])

    fig = plt.figure(figsize=(14, 12))
    gs = gridspec.GridSpec(2, 1, height_ratios=[1.2, 1])

    ax1 = plt.subplot(gs[0])
    ax1.plot(strategy_curve.index, strategy_curve.values, color='purple', linewidth=2.5, label=f'AI Strategy (Return: +{ai_return_pct:.2f}%)')
    ax1.plot(qqq_scaled.index, qqq_scaled.values, color='orange', linewidth=2, linestyle='--', alpha=0.8, label=f'QQQ Benchmark (Return: +{qqq_return_pct:.2f}%)')
    ax1.set_title(f'Performance Comparison (Seed {TARGET_SEED})\nAI: ${final_val:,.0f} vs QQQ: ${qqq_final_val:,.0f}', fontsize=16, fontweight='bold')
    ax1.legend(loc='upper left')
    ax1.grid(True, alpha=0.3)

    ax2 = plt.subplot(gs[1], sharex=ax1)
    all_assets = ['CASH'] + stocks
    for date_idx, row in sel_df.iterrows():
        date = row['Date']
        picks = [row['Pick1'], row['Pick2'], row['Pick3']]
        if 'CASH' in picks:
            ax2.scatter(date, 'CASH', color='gray', s=100, marker='s')
        else:
            for pick in picks:
                if pick in all_assets:
                    ax2.scatter(date, pick, color='royalblue', s=60, alpha=0.6)

    ax2.set_title('AI Monthly Stock Selection', fontsize=14)
    ax2.set_yticks(range(len(all_assets)))
    ax2.set_yticklabels(all_assets)
    ax2.grid(True, alpha=0.3, axis='x')

    plt.tight_layout()
    plt.show()

    print("="*50)
    print(f"ğŸ“Š [ìµœì¢… ê²°ê³¼] Seed {TARGET_SEED}")
    print(f" - AI ìµœì¢… ìì‚°: ${final_val:,.2f} (+{ai_return_pct:.2f}%)")
    print(f" - QQQ ìµœì¢… ìì‚°: ${qqq_final_val:,.2f} (+{qqq_return_pct:.2f}%)")
    print(f"ğŸ‘‰ ê²°ê³¼: {'AI ìŠ¹ë¦¬ ğŸ†' if ai_return_pct > qqq_return_pct else 'QQQ ìŠ¹ë¦¬'}")
    print("="*50)

if __name__ == "__main__":
    hist, dts, sel_h, st_list, qqq_n = run_simulation_improved(TARGET_SEED)
    plot_final_results(hist, dts, sel_h, st_list, qqq_n)
